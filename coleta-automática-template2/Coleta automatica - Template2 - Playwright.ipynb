{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta automatica - Template2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o objetivo de iniciar um estudo acerca do reaproveitamento de coletores dentro de um mesmo template, esse notebook discute uma abordagem inicial a ser realizada no Template 2. Para isso, utiliza-se as seguintes bibliotecas:\\\n",
    "-BeaufifulSoup para gerar links \\\n",
    "-Selenium e Playwright para realização dos processamentos dinâmicos\\\n",
    "Casos isoladas como baixar pdfs que abrem em nova guia são tratados usando a ferramenta de automação PyAutogui.\n",
    "\n",
    "Essa estratégia de coleta seria a consequência de outra aplicação a ser desenvolvida: clusterização de páginas de acordo com o coletor necessário para aquisição do dado. \n",
    "\n",
    "Nesse caso, as páginas foram separadas manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import urllib3\n",
    "import pyautogui\n",
    "import asyncio\n",
    "import time\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException, ElementNotInteractableException\n",
    "\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, encontram-se as cidades e as respectivas urls bases. Também há as subtags a serem coletadas. Essas subtags são adaptadas para serem usadas no casamento de padrão com as urls das páginas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cidades = ['Novo Oriente de Minas',\n",
    "     'Frei Gaspar',\n",
    "     'Fronteira dos Vales',\n",
    "     'Chapada do Norte',\n",
    "     'Sardoá',\n",
    "     'Bertópolis',\n",
    "     'Cuparaque',\n",
    "     'Coroaci',\n",
    "     'Machacalis',\n",
    "     'Periquito',\n",
    "     'Itabirinha',\n",
    "     'São Sebastião do Maranhão',\n",
    "     'Caraí',\n",
    "     'Ataléia',\n",
    "     'Ouro Verde de Minas',\n",
    "     'Itaipé',\n",
    "     'Umburatiba',\n",
    "     'Marilac',\n",
    "     'Jordânia',\n",
    "     'São João Evangelista',\n",
    "     'Bandeira',\n",
    "     'Tumiritinga',\n",
    "     'Santa Efigênia de Minas',\n",
    "     'Pavão',\n",
    "     'Pescador',\n",
    "     'Cantagalo',\n",
    "     'Santo Antônio do Jacinto']\n",
    "\n",
    "tags = [\"licitacoes\", \"contratos\", \"empenhos\", \"receitas\", \"folha\", \"pagamentos\", \n",
    "        \"liquidacoes\",\"diarias\", \"obras\", \"relatorio\", \"dispensas\", \"despesas-com-pessoal\", \"editais\"]\n",
    "subpastas = [\"screenshots\", \"files\", \"htmls\"]\n",
    "\n",
    "cidades_urls = {'Novo Oriente de Minas': [\"https://novoorientedeminas.mg.gov.br/transparencia\", \"https://novoorientedeminas.mg.gov.br/tran\"],\n",
    "     'Frei Gaspar': [\"https://freigaspar.mg.gov.br/transparencia\", \"https://freigaspar.mg.gov.br/tran\"],\n",
    "     'Fronteira dos Vales': [\"https://fronteiradosvales.mg.gov.br/transparencia\", \"https://fronteiradosvales.mg.gov.br/tran\"],\n",
    "     'Chapada do Norte': [\"https://chapadadonorte.mg.gov.br/transparencia\", \"https://chapadadonorte.mg.gov.br/tran\"],\n",
    "     'Sardoá': [\"https://sardoa.mg.gov.br/transparencia\", \"https://sardoa.mg.gov.br/tran\"],\n",
    "     'Bertópolis': [\"https://bertopolis.mg.gov.br/transparencia\", \"https://bertopolis.mg.gov.br/tran\"],\n",
    "     'Cuparaque': [\"https://cuparaque.mg.gov.br/transparencia\", \"https://cuparaque.mg.gov.br/tran\"],\n",
    "     'Coroaci': [\"https://coroaci.mg.gov.br/transparencia\", \"https://coroaci.mg.gov.br/tran\"],\n",
    "     'Machacalis': [\"https://machacalis.mg.gov.br/transparencia\", \"https://machacalis.mg.gov.br/tran\"],\n",
    "      #'Periquito':\n",
    "     'Itabirinha': [\"https://itabirinha.mg.gov.br/transparencia\", \"https://itabirinha.mg.gov.br/tran\"],\n",
    "     'São Sebastião do Maranhão': [\"https://saosebastiaodomaranhao.mg.gov.br/transparencia\", \"https://saosebastiaodomaranhao.mg.gov.br/tran\"],\n",
    "     'Caraí': [\"https://carai.mg.gov.br/transparencia\", \"https://carai.mg.gov.br/tran\"],\n",
    "     'Ataléia': [\"https://ataleia.mg.gov.br/transparencia\", \"https://ataleia.mg.gov.br/tran\"],\n",
    "     'Ouro Verde de Minas': [\"https://ouroverdedeminas.mg.gov.br/transparencia\", \"https://ouroverdedeminas.mg.gov.br/tran\"],\n",
    "     'Itaipé': [\"https://itaipe.mg.gov.br/transparencia\", \"https://itaipe.mg.gov.br/tran\"],\n",
    "     'Umburatiba': [\"https://umburatiba.mg.gov.br/transparencia\", \"https://umburatiba.mg.gov.br/tran\"],\n",
    "     'Marilac': [\"https://marilac.mg.gov.br/transparencia\", \"https://marilac.mg.gov.br/tran\"],\n",
    "     'Jordânia': [\"https://jordania.mg.gov.br/transparencia\", \"https://jordania.mg.gov.br/tran\"],\n",
    "     'São João Evangelista': [\"https://sje.mg.gov.br/transparencia\", \"https://sje.mg.gov.br/tran\"],\n",
    "     'Bandeira': [\"https://bandeira.mg.gov.br/transparencia\", \"https://bandeira.mg.gov.br/tran\"],\n",
    "     'Tumiritinga': [\"https://tumiritinga.mg.gov.br/transparencia\", \"https://tumiritinga.mg.gov.br/tran\"],\n",
    "     'Santa Efigênia de Minas': [\"https://santaefigenia.mg.gov.br/transparencia\", \"https://santaefigenia.mg.gov.br/tran\"],\n",
    "     'Pavão': [\"https://pavao.mg.gov.br/transparencia\", \"https://pavao.mg.gov.br/tran\"],\n",
    "     'Pescador': [\"https://pescador.mg.gov.br/transparencia\", \"https://pescador.mg.gov.br/tran\"],\n",
    "     'Cantagalo': [\"https://cantagalo.mg.gov.br/transparencia\", \"https://cantagalo.mg.gov.br/tran\"],\n",
    "     'Santo Antônio do Jacinto': [\"https://www.santoantoniodojacinto.mg.gov.br/transparencia\", \"https://www.santoantoniodojacinto.mg.gov.br/tran\"]}\n",
    "\n",
    "pasta_raiz = os.getcwd()\n",
    "pasta_template = \"/Coletas\" + \"/template2/\"\n",
    "pasta_template_completo = pasta_raiz + pasta_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Coletas/template2/\n"
     ]
    }
   ],
   "source": [
    "print(pasta_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir cria as pastas para guardar adequadamente cada um dos dados coletados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pastes():\n",
    "\n",
    "    try:\n",
    "        os.mkdir(pasta_raiz + \"/Coletas\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(pasta_raiz + \"/Coletas\" + \"/template2/\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    for cidade in cidades:\n",
    "        try:\n",
    "            os.mkdir(pasta_template_completo + cidade)\n",
    "            for tag in tags:\n",
    "                os.mkdir(pasta_template_completo  + cidade + \"/\" + tag)\n",
    "                for sub in subpastas:\n",
    "                    os.mkdir(pasta_template_completo  + cidade + \"/\" + tag + \"/\" + sub)\n",
    "        except FileExistsError:\n",
    "            continue\n",
    "    \n",
    "create_pastes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletor 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse primeiro coletor é específico para baixar urls que representam pdfs. Assim, utiliza-se o Selenium para abrir a url e o PyAutogui para realizar o download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coletor_pdf(cidade, subtag, url):\n",
    "\n",
    "    arq = open(\"log.txt\", \"w\")\n",
    "    arq.write(\"Coletando \" + url)\n",
    "    arq.close()\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    chrome_options.add_experimental_option('prefs', {\n",
    "    \"download.default_directory\": pasta_template_completo + cidade + \"/\"+ subtag + \"/files\",#IMPORTANT - ENDING SLASH V IMPORTANT, #Change default directory for downloads\n",
    "    \"download.prompt_for_download\": False, #To auto download the file\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"plugins.always_open_pdf_externally\": True #It will not show PDF directly in chrome\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options = chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)\n",
    "    pyautogui.hotkey('ctrl', 'b')\n",
    "    time.sleep(2)\n",
    "    pyautogui.press('enter')\n",
    "    driver.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste unitário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coletor_pdf(\"Frei Gaspar\", \"relatorio\", \"https://digitaliza-institucional.s3.us-east-2.amazonaws.com/municipio-de-cantagalo/rgf_rreo/Relat%C3%B3rio%20Resumido%20de%20Execu%C3%A7%C3%A3o%20Or%C3%A7ament%C3%A1ria%20Simplificado%20-%201%C2%BA%20bimestre-06-07-2021%20-%20nwsBT.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletor 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O coletor 2 salva o html da página. Isso ocorre pois o dado disponibilizado possivelmente não pode ser baixado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def coletor_html(cidade, subtag, url): \n",
    "        \n",
    "    arq = open(\"log.txt\", \"w\")\n",
    "    arq.write(\"Coletando \" + url)\n",
    "    arq.close()\n",
    "        \n",
    "    playwright = await async_playwright().start()\n",
    "    browser = await playwright.chromium.launch(headless = True)\n",
    "    page = await browser.new_page()\n",
    "    await page.goto(url)\n",
    "    conteudo = await page.content()\n",
    "\n",
    "    url_aux = url.replace(\".\", \"\")\n",
    "    url_aux = url_aux.replace(\"/\", \"\")\n",
    "    url_aux = url_aux.replace(\":\", \"\")\n",
    "    subtag = subtag.lower()\n",
    "    \n",
    "    with open(pasta_template_completo+cidade+\"/\"+subtag+\"/\"+\"htmls/\"+url_aux + \".html\", \"w\") as file:\n",
    "        file.write(conteudo)\n",
    "    file.close()\n",
    "    \n",
    "    await page.close()\n",
    "    await browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste unitário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-4' coro=<coletor_html() running at /tmp/ipykernel_4595/1489137232.py:1>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task(coletor_html(\"Novo Oriente de Minas\", \"empenhos\", \"https://novoorientedeminas.mg.gov.br/transparencia/liquidacoes/exibir/2022/06/81808\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletor 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O coletor a seguir tenta clicar em um botão csv na página (a maioria das coletas do template é feita somente com esse passo), caso levante um erro (se o botão estiver indisponível, por exemplo) ele salva a página em formato html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def coletor_geral(cidade, subtag, url, loop): \n",
    "\n",
    "    arq = open(\"log.txt\", \"w\")\n",
    "    arq.write(\"Coletando \" + url)\n",
    "    arq.close()\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        playwright = await async_playwright().start()\n",
    "        browser = await playwright.chromium.launch(headless = True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        \n",
    "        async with page.expect_download() as download_info:\n",
    "            await page.locator(\"button:has-text(\\\"CSV\\\")\").click()\n",
    "        download = await download_info.value\n",
    "\n",
    "        subtag = subtag.lower()\n",
    "        \n",
    "        filename = await download.path()\n",
    "        complement = str(filename).split(\"/\")[-1]\n",
    "        \n",
    "        await page.screenshot(path=pasta_template_completo + cidade + \"/\" + subtag + \"/\" + \n",
    "                              \"screenshots/\" + \"page\"+complement+\".png\")\n",
    "        await download.save_as(pasta_template_completo + cidade + \"/\" + subtag + \"/files/\" + complement)\n",
    "        \n",
    "        await page.close()\n",
    "        await browser.close()\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        await page.close()\n",
    "        await browser.close()\n",
    "        \n",
    "        loop.create_task(coletor_html(cidade, subtag, url))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste 'try':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-8' coro=<coletor_geral() running at /tmp/ipykernel_4595/2912153009.py:1>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task(coletor_geral(\"Novo Oriente de Minas\", \"liquidacoes\", \"https://novoorientedeminas.mg.gov.br/transparencia/liquidacoes\", loop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste 'except':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-6' coro=<coletor_geral() running at /tmp/ipykernel_7818/1599326995.py:1>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task(coletor_geral(\"Novo Oriente de Minas\", \"liquidacoes\", \"https://novoorientedeminas.mg.gov.br/transparencia/liquidacoes/exibir/2022/06/81808\", loop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorador de links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É nessa função que iremos gerar os links correspondentes a cada subtag para cada um dos municípios considerados. Esses links são separados e retornados em um dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(pages, depth, tags, restriction):\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    already_visited = set(pages)\n",
    "    \n",
    "    dic = {}\n",
    "    for tag in tags:\n",
    "        dic[tag] = set()\n",
    "\n",
    "    for i in range(depth):\n",
    "        new_pages = set()\n",
    "        print(\"Actual depth: \" + str(i))\n",
    "\n",
    "        for page in pages:\n",
    "            http = urllib3.PoolManager()\n",
    "            try:\n",
    "                page_data = http.request('GET', page)\n",
    "                \n",
    "            except:\n",
    "                print(\"Error: \" + page)\n",
    "                continue\n",
    "\n",
    "            arq = open(\"log.txt\", \"w\")\n",
    "            arq.write(\"Explorando \" + page)\n",
    "            arq.close()\n",
    "\n",
    "            soup = BeautifulSoup(page_data.data, \"lxml\")\n",
    "            already_visited.add(page)\n",
    "\n",
    "            links = soup.find_all('a')\n",
    "        \n",
    "            for link in links:\n",
    "                \n",
    "                if(\"href\" in link.attrs):\n",
    "                    url = urljoin(page, str(link.get('href')))\n",
    "\n",
    "                    if url.find(\"'\") != -1:\n",
    "                        continue\n",
    "\n",
    "                    url = url.split(\"#\")[0]\n",
    "\n",
    "                #Restriction to prevent the crawler get out the base url or to consider pdf urls\n",
    "                if url.startswith(restriction) or url.startswith(\"https://digitaliza\"):\n",
    "                    if \"exibir\" not in url:\n",
    "                        new_pages.add(url)\n",
    "                    for tag in tags:\n",
    "                        if tag in url:\n",
    "                            dic[tag].add(url)\n",
    "                            #if tag == \"obras\":\n",
    "                             #   dic[tag].add(url)\n",
    "                            #elif \"detalhes\" in url:\n",
    "                             #   dic[tag].add(url)\n",
    "                    if \"pdf\" in url:\n",
    "                        dic[\"relatorio\"].add(url)\n",
    "            \n",
    "                \n",
    "                \n",
    "\n",
    "        pages = new_pages.difference(already_visited)\n",
    "        print(pages)\n",
    "\n",
    "        print(\"Number of links visited: \" +  str(len(already_visited)))\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coleta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir junta todos os passos anteriores. Assim, ela recebe uma cidade, sua url bases e as restrições de geração de links e, para cada link gerado, realiza a coleta do dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colect(cidade, url, restriction, loop):\n",
    "    \n",
    "    links = crawl([url], 5, tags, restriction)\n",
    "    \n",
    "    for key, value in links.items():\n",
    "        for link in value:\n",
    "            if \"pdf\" in link:\n",
    "                coletor_pdf(cidade, key, link)\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                loop.create_task(coletor_geral(cidade, key, link, loop))\n",
    "                await asyncio.sleep(12)\n",
    "    \n",
    "    print(\"Relatorio de coleta da cidade \" + \"/\" + cidade + \"/\")\n",
    "    for subtag in os.listdir(pasta_template_completo+ cidade):\n",
    "        print(\"Coletado \" + str(len(os.listdir(pasta_template_completo + cidade + \"/\" + subtag + \"/files\"))) + \n",
    "              \" documentos na subtag \" + subtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste unitário\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual depth: 0\n",
      "{'https://fronteiradosvales.mg.gov.br/transparencia/editais', 'https://fronteiradosvales.mg.gov.br/transparencia/mapa', 'https://fronteiradosvales.mg.gov.br/transparencia/dispensas', 'https://fronteiradosvales.mg.gov.br/transparencia/receitas', 'https://fronteiradosvales.mg.gov.br/transparencia/contratos', 'https://fronteiradosvales.mg.gov.br/transparencia/obras', 'https://fronteiradosvales.mg.gov.br/transparencia/relatorios', 'https://fronteiradosvales.mg.gov.br/transparencia/folhas-de-pagamento', 'https://fronteiradosvales.mg.gov.br/transparencia/coronavirus', 'https://fronteiradosvales.mg.gov.br/transparencia/licitacoes', 'https://fronteiradosvales.mg.gov.br/transparencia/despesas-com-pessoal', 'https://fronteiradosvales.mg.gov.br/transparencia/empenhos', 'https://fronteiradosvales.mg.gov.br/transparencia/diarias', 'https://fronteiradosvales.mg.gov.br/transparencia/sobre', 'https://fronteiradosvales.mg.gov.br/transparencia/pagamentos', 'https://fronteiradosvales.mg.gov.br/transparencia/liquidacoes'}\n",
      "Number of links visited: 1\n",
      "Relatorio de coleta da cidade /Fronteira dos Vales/\n",
      "Coletado 0 documentos na subtag despesas-com-pessoal\n",
      "Coletado 0 documentos na subtag dispensas\n",
      "Coletado 0 documentos na subtag obras\n",
      "Coletado 0 documentos na subtag licitacoes\n",
      "Coletado 0 documentos na subtag contratos\n",
      "Coletado 0 documentos na subtag folha\n",
      "Coletado 0 documentos na subtag receitas\n",
      "Coletado 0 documentos na subtag diarias\n",
      "Coletado 0 documentos na subtag relatorio\n",
      "Coletado 0 documentos na subtag pagamentos\n",
      "Coletado 0 documentos na subtag editais\n",
      "Coletado 0 documentos na subtag empenhos\n",
      "Coletado 0 documentos na subtag liquidacoes\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "colect('Fronteira dos Vales', \"https://fronteiradosvales.mg.gov.br/transparencia\", \"https://fronteiradosvales.mg.gov.br/tran\", loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução em massa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "for key, value in cidades_urls.items():\n",
    "    colect(key, value[0], value[1], loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerarRelatorio(cidade, url, restriction):\n",
    "    \n",
    "    global total\n",
    "    \n",
    "    print(\"Relatorio de coleta da cidade \" + \"--\" + cidade + \"--\")\n",
    "    for subtag in os.listdir(pasta_template_completo+ cidade):\n",
    "        print(\"Coletado \" + str(len(os.listdir(pasta_template_completo + cidade + \"/\" + subtag + \"/files\"))) + \n",
    "              \" documentos na subtag \" + subtag)\n",
    "        print(\"Coletado \" + str(len(os.listdir(pasta_template_completo + cidade + \"/\" + subtag + \"/htmls\"))) + \n",
    "              \" htmls na subtag \" + subtag)\n",
    "        total += len(os.listdir(pasta_template_completo + cidade + \"/\" + subtag + \"/files\"))\n",
    "        total += len(os.listdir(pasta_template_completo + cidade + \"/\" + subtag + \"/htmls\"))\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for key, value in cidades_urls.items():\n",
    "    gerarRelatorio(key, value[0], value[1])\n",
    "print(\"Total de documentos coletados: \" + str(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materiais úteis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuração Selenium:\n",
    "https://tecadmin.net/setup-selenium-chromedriver-on-ubuntu/\n",
    "\n",
    "Configuração e tutorial Playwright:\n",
    "https://playwright.dev/python/docs/intro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
